# -Deep-Learning-for-Audio-with-Python

## 01. Artificial Neuron Implementation
- **ëª©í‘œl:** ì‹ ê²½í•™ìŠµë§ì˜ ê¸°ì´ˆ êµ¬ì„± ì´í•´.
- **Process:**
  1. Receive multiple inputs.
  2. Apply weights to each input.
  3. Calculate the weighted sum.
  4. Use Sigmoid activation function to squeeze the result between 0 and 1.
- ê°€ì¤‘ì¹˜ í•¨: $h = \sum w_i x_i$
- Sigmoid: $y = \frac{1}{1 + e^{-h}}$
- **Tools:** Python `math` module.

## 02. Multilayer Perceptron Implementation
- **Goal:** ì—¬ëŸ¬ ì€ë‹‰ì¸µì„ ê°€ì§„ ì‹ ê²½ë§ êµ¬ì¡° ì„¤ê³„ ë° ìˆœì „íŒŒ êµ¬í˜„.
- **Process:**
  1. ì…ë ¥ì¸µ, ì€ë‹‰ì¸µ ë¦¬ìŠ¤íŠ¸, ì¶œë ¥ì¸µì„ í¬í•¨í•œ ì „ì²´ ë ˆì´ì–´ êµ¬ì¡° ì •ì˜.
  2. `numpy.random.randn`ì„ ì´ìš©í•´ ê° ì¸µ ì‚¬ì´ì˜ ê°€ì¤‘ì¹˜ í–‰ë ¬ ì´ˆê¸°í™”.
  3. `numpy.dot` í–‰ë ¬ ê³±ì…ˆì„ í†µí•´ ì¸µê°„ ë°ì´í„° íë¦„ êµ¬í˜„.
  4. ë°˜ë³µë¬¸ì„ í†µí•´ ê° ì¸µì— Sigmoid í™œì„±í™” í•¨ìˆ˜ ì ìš© ë° ìµœì¢… ê²°ê³¼ ë„ì¶œ.
- **Tools:** Python `NumPy`.

## 02.1 Structure Simulation

ë³¸ í”„ë¡œì íŠ¸ì˜ ë™ì‘ ì›ë¦¬ë¥¼ ì´í•´í•˜ê¸° ìœ„í•´ 2(ì…ë ¥)-2(ì€ë‹‰)-1(ì¶œë ¥) ë ˆì´ì–´ êµ¬ì¡°ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í•œ ì—°ì‚° ê³¼ì •ì„ ì •ë¦¬í•©ë‹ˆë‹¤.

### 1. ì „ì œ ì¡°ê±´ (Notation)
* **Activations:** $a_0$ (ì…ë ¥ì¸µ), $a_1$ (ì€ë‹‰ì¸µ), $a_2$ (ì¶œë ¥ì¸µ)
* **Weights:** $W_0$ (ì…ë ¥-ì€ë‹‰ ê°€ì¤‘ì¹˜), $W_1$ (ì€ë‹‰-ì¶œë ¥ ê°€ì¤‘ì¹˜)
* **Functions:** $\sigma$ (Sigmoid í™œì„±í™” í•¨ìˆ˜), $\sigma'$ (Sigmoid ë¯¸ë¶„)
* **Target:** $y$ (ì‹¤ì œ ì •ë‹µ)

---

### 2. ìˆœì „íŒŒ (Forward Propagation)
ë°ì´í„°ê°€ ì…ë ¥ì¸µì—ì„œ ì¶œë ¥ì¸µìœ¼ë¡œ íë¥´ë©° ì˜ˆì¸¡ê°’ $a_2$ë¥¼ ë„ì¶œí•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤.

1.  **ì€ë‹‰ì¸µ ê³„ì‚°:**
    $$h_1 = a_0 \cdot W_0$$
    $$a_1 = \sigma(h_1)$$
2.  **ì¶œë ¥ì¸µ ê³„ì‚°:**
    $$h_2 = a_1 \cdot W_1$$
    $$a_2 = \sigma(h_2)$$



---

### 3. ì—­ì „íŒŒ (Backpropagation)
ì˜¤ì°¨ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë’¤ì—ì„œë¶€í„° ê° ì¸µì˜ ê¸°ì—¬ë„(Delta)ë¥¼ ê³„ì‚°í•˜ê³  ê°€ì¤‘ì¹˜ë¥¼ ìˆ˜ì •í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤.

#### **Step 1: ì¶œë ¥ì¸µ (Output Layer)**
1.  **ì¶œë ¥ì¸µ ì—ëŸ¬ ($error_2$):** ì‹¤ì œê°’ê³¼ ì˜ˆì¸¡ê°’ì˜ ì°¨ì´
    $$error_2 = y - a_2$$
2.  **ì¶œë ¥ì¸µ ë¸íƒ€ ($\delta_2$):** ì—ëŸ¬ì— ì¶œë ¥ì¸µ ê¸°ìš¸ê¸°ë¥¼ ì ìš© (Hadamard product)
    $$\delta_2 = error_2 \odot \sigma'(a_2)$$
3.  **ê°€ì¤‘ì¹˜ $W_1$ ìˆ˜ì •ì•ˆ ($Deriv_1$):**
    $$Deriv_1 = a_1^T \cdot \delta_2$$

#### **Step 2: ì€ë‹‰ì¸µ (Hidden Layer)**
1.  **ì€ë‹‰ì¸µ ì—ëŸ¬ ($error_1$):** ì¶œë ¥ì¸µ ë¸íƒ€ê°€ ê°€ì¤‘ì¹˜ë¥¼ íƒ€ê³  ì—­ì „íŒŒë¨
    $$error_1 = \delta_2 \cdot W_1^T$$
2.  **ì€ë‹‰ì¸µ ë¸íƒ€ ($\delta_1$):** ë°°ë‹¬ëœ ì—ëŸ¬ì— ì€ë‹‰ì¸µ ê¸°ìš¸ê¸°ë¥¼ ì ìš© (Hadamard product)
    $$\delta_1 = error_1 \odot \sigma'(a_1)$$
3.  **ê°€ì¤‘ì¹˜ $W_0$ ìˆ˜ì •ì•ˆ ($Deriv_0$):**
    $$Deriv_0 = a_0^T \cdot \delta_1$$



---

### 4. ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸ (Weight Update)
ê³„ì‚°ëœ ë¯¸ë¶„ê°’($Deriv$)ê³¼ í•™ìŠµë¥ ($\eta$)ì„ ì‚¬ìš©í•˜ì—¬ ê°€ì¤‘ì¹˜ë¥¼ ì‹¤ì œë¡œ ìˆ˜ì •í•©ë‹ˆë‹¤.

* $W_1 = W_1 + \eta \cdot Deriv_1$
* $W_0 = W_0 + \eta \cdot Deriv_0$

---

### ğŸ’¡ í•µì‹¬ ì›ë¦¬ ìš”ì•½
* **$\delta$ (Delta):** ê° ì¸µì˜ ë‰´ëŸ°ì´ ê²°ê³¼ì— ëŒ€í•´ ì±…ì„ì ¸ì•¼ í•  **ì˜¤ì°¨ì˜ ë³¸ì²´**ì…ë‹ˆë‹¤. í•­ìƒ `error âŠ™ f'(a)`ì˜ ì¼ê´€ëœ í˜•íƒœë¡œ ê³„ì‚°ë©ë‹ˆë‹¤.
* **$\cdot$ (Dot Product):** ì—ëŸ¬ ì‹ í˜¸ë¥¼ ì• ì¸µìœ¼ë¡œ **ì „ë‹¬**í•˜ê±°ë‚˜, ê°€ì¤‘ì¹˜ ì „ì²´ì˜ **ìˆ˜ì • ì§€ë„**ë¥¼ ê·¸ë¦´ ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
* **$\odot$ (Hadamard Product):** í•´ë‹¹ ì¸µì˜ í™œì„±í™” í•¨ìˆ˜ íŠ¹ì„±(ê¸°ìš¸ê¸°)ì„ ì—ëŸ¬ì— **í•„í„°ë§**í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.

### ğŸ”¢ ìˆ˜ì¹˜ ê¸°ë°˜ ì‹œë®¬ë ˆì´ì…˜ (Numerical Example)

2-2-1 êµ¬ì¡°ì—ì„œ ì‹¤ì œ ìˆ«ìê°€ ì–´ë–»ê²Œ ê³„ì‚°ë˜ê³  ì „ë‹¬ë˜ëŠ”ì§€ ë‹¨ê³„ë³„ë¡œ ì‚´í´ë´…ë‹ˆë‹¤.

#### **1. ìˆœì „íŒŒ (Forward)**
* **Input ($a_0$):** $[1.0, 2.0]$
* **Weights ($W_1$):** ëª¨ë‘ $0.5$ë¡œ ê°€ì • (ì€ë‹‰-ì¶œë ¥ ê°€ì¤‘ì¹˜)
* **Target ($y$):** $1.0$ (ëª©í‘œ ì •ë‹µ)
* **Output ($a_2$):** $0.68$ (ì˜ˆì¸¡ê°’), **Hidden ($a_1$):** $[0.6, 0.7]$

#### **2. ì—­ì „íŒŒ (Backward) - ì¶œë ¥ì¸µ**
1.  **$error_2$ ê³„ì‚°:**
    $$error_2 = y - a_2 = 1.0 - 0.68 = \mathbf{0.32}$$
2.  **$\delta_2$ ê³„ì‚° (ì˜¤ì°¨ $\odot$ ê¸°ìš¸ê¸°):**
    * $\sigma'(a_2) = 0.68 \times (1 - 0.68) \approx 0.22$
    $$\delta_2 = error_2 \odot \sigma'(a_2) = 0.32 \times 0.22 = \mathbf{0.07}$$
3.  **$Deriv_1$ ì‘ì„± (ì´ì „ ì¸µ ì¶œë ¥ $a_1^T$ì™€ ë¸íƒ€ $\delta_2$ì˜ ë‚´ì ):**
   
$$
\text{Deriv}_1 = \left[ \begin{matrix} 0.6 \\\\ 0.7 \end{matrix} \right] \cdot [0.07] = \left[ \begin{matrix} 0.042 \\\\ 0.049 \end{matrix} \right]
$$

#### **3. ì—­ì „íŒŒ (Backward) - ì€ë‹‰ì¸µ**
1.  **$error_1$ ì „ë‹¬ (ì—ëŸ¬ ë¦´ë ˆì´):**
    * $\delta_2$ê°€ ê°€ì¤‘ì¹˜ $W_1$ì„ íƒ€ê³  ì—­í–‰
    $$error_1 = \delta_2 \cdot W_1^T = [0.07] \cdot [0.5, 0.5] = \mathbf{[0.035, 0.035]}$$
2.  **$\delta_1$ ê³„ì‚° (ë°°ë‹¬ëœ ì—ëŸ¬ $\odot$ ì€ë‹‰ì¸µ ê¸°ìš¸ê¸°):**
    * $\sigma'(a_1) = [0.6(1-0.6), \; 0.7(1-0.7)] = [0.24, 0.21]$
    $$\delta_1 = error_1 \odot \sigma'(a_1) = [0.035, 0.035] \odot [0.24, 0.21] = \mathbf{[0.0084, 0.00735]}$$
3.  **$Deriv_0$ ì‘ì„± (ì…ë ¥ê°’ $a_0^T$ì™€ ë¸íƒ€ $\delta_1$ì˜ ë‚´ì ):**
   
$$
Deriv_0 = \begin{bmatrix} 1.0 \\\\ 2.0 \end{bmatrix} \cdot [0.0084, 0.00735]
$$

$$
Deriv_0 = \mathbf{\begin{bmatrix} 0.0084 & 0.00735 \\\\ 0.0168 & 0.0147 \end{bmatrix}}
$$

## 05. Training & Learning Implementation
- **Goal:** ë°ì´í„° ì„¸íŠ¸ë¥¼ ë°˜ë³µ í•™ìŠµì‹œì¼œ ê°€ì¤‘ì¹˜ë¥¼ ì‹¤ì œë¡œ ìˆ˜ì •í•¨.
- **Process:**
  1. **ë°ì´í„° ê³µê¸‰:** `zip`ì„ ì´ìš©í•´ `inputs`ì™€ `targets`ë¥¼ í•œ ìŒì˜ ì„¸íŠ¸ë¡œ ë¬¶ì–´ êº¼ëƒ„.
  2. **ë°˜ë³µ í•™ìŠµ:** `epochs` íšŸìˆ˜ë§Œí¼ ì „ì²´ ë°ì´í„°ë¥¼ ë°˜ë³µí•´ì„œ ìˆ˜í–‰í•¨.
  3. **ê°€ì¤‘ì¹˜ ìˆ˜ì •:** `gradient_descent`ë¥¼ í†µí•´ ê³„ì‚°ëœ ë¯¸ë¶„ê°’ê³¼ í•™ìŠµë¥ ì„ ì—°ì‚°í•˜ì—¬ ê°€ì¤‘ì¹˜ë¥¼ ì—…ë°ì´íŠ¸í•¨.

### ğŸ’¡ í•™ìŠµ ë° ì˜¤ì°¨ ë¶„ì„ ë…¼ë¦¬
- **ë°ì´í„° ì¶”ì¶œ ë°©ì‹:** `zip`ì€ ë¬¸ì œì™€ ì •ë‹µì„ í•˜ë‚˜ë¡œ ë¬¶ì–´ì£¼ê³ , ë£¨í”„ë¥¼ ëŒë©° ê°ê°ì˜ ì„¸íŠ¸ë¥¼ êº¼ë‚´ í•¨ìˆ˜ ì¸ìë¡œ ì‚¬ìš©í•¨.
- **ì—ëŸ¬ ëˆ„ì  ë° í‰ê· í™”:** - ê° ë£¨í”„ë§ˆë‹¤ ë°œìƒí•˜ëŠ” `mse` ì˜¤ì°¨ë¥¼ `sum_error`ì— ìŒ“ìŒ.
  - í•œ epoch ë£¨í”„ê°€ ëë‚  ë•Œ, ëˆ„ì ëœ ê°’ì„ **ì‚¬ìš©í•œ ë°ì´í„° ì„¸íŠ¸ì˜ ìˆ˜(`len(inputs)`)**ë¡œ ë‚˜ëˆ ì•¼ ë°ì´í„°ë‹¹ í‰ê·  ì˜¤ì°¨ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŒ.

## 06. Final Simulation Result & Test
- **Task:** ë§ì…ˆ ì—°ì‚° í•™ìŠµ ($x_1 + x_2$)
- **Dataset:** `random()/2`ë¥¼ ì‚¬ìš©í•´ í•©ì´ 1ì„ ë„˜ì§€ ì•ŠëŠ” 1,000ê°œì˜ ë°ì´í„° ìƒì„±.
- **Training:** 50 ì—í¬í¬ ë™ì•ˆ ì´ 50,000ë²ˆì˜ í•™ìŠµ ìˆ˜í–‰.

## 07. TensorFlow í™œìš© ëª¨ë¸ êµ¬í˜„ ë° ë¹„êµ (MLP_TF)

ê¸°ì¡´ì— ì§ì ‘ íŒŒì´ì¬ìœ¼ë¡œ êµ¬í˜„í–ˆë˜ ì‹ ê²½ë§ ë¡œì§ì„ **TensorFlow/Keras** ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ í˜„ëŒ€ì ì¸ ë°©ì‹ìœ¼ë¡œ ì¬êµ¬ì„±í•˜ì˜€ìŠµë‹ˆë‹¤.

### 1ï¸âƒ£ ëª¨ë¸ êµ¬ì„± ë° ë¹„êµ (2-5-1 MLP)
| êµ¬ë¶„ | ë°‘ë°”ë‹¥ë¶€í„° ì§œê¸° (Raw Python) | TensorFlow Keras ì‚¬ìš© |
|:---:|:---|:---|
| **ëª¨ë¸ ì •ì˜** | `MLP` í´ë˜ìŠ¤ ìƒì„±, `Layer` ë¦¬ìŠ¤íŠ¸ ê´€ë¦¬ | `tf.keras.Sequential`ë¡œ ì¸µì„ ì°¨ë¡€ë¡œ ìŒ“ìŒ |
| **ìˆœì „íŒŒ** | `_sigmoid` í•¨ìˆ˜ ë° í–‰ë ¬ ê³± ì§ì ‘ êµ¬í˜„ | `layers.Dense(activation="sigmoid")` ìë™ ì²˜ë¦¬ |
| **ì…ë ¥ ì„¤ì •** | ì…ë ¥ ë²¡í„° í¬ê¸°ì— ë§ì¶° ê°€ì¤‘ì¹˜ í–‰ë ¬ ì´ˆê¸°í™” | `input_dim=2`ë¥¼ í†µí•´ ì²« ë²ˆì§¸ ì¸µì˜ ì…ë ¥ ì •ì˜ |

### 2ï¸âƒ£ í•µì‹¬ í•¨ìˆ˜ ë° íŒŒë¼ë¯¸í„° ìš”ì•½

* **Optimizer (ìµœì í™”):** `tf.keras.optimizers.SGD(learning_rate=0.1)`
    * **ì˜ë¯¸:** ìš°ë¦¬ê°€ ì§ì ‘ ë¯¸ë¶„($Gradient$)í•˜ì—¬ ê°€ì¤‘ì¹˜ë¥¼ ì—…ë°ì´íŠ¸í–ˆë˜ ê³¼ì •ì„ ìë™í™”í•¨.
    * **Learning Rate (0.1):** ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸ ì‹œì˜ **'ë³´í­'**. ìˆ˜ë™ êµ¬í˜„ ì‹œ $W = W - \eta \cdot \nabla L$ ê³µì‹ì˜ **$\eta$** ê°’ê³¼ ë™ì¼í•¨.
* **Loss Function (ì†ì‹¤ í•¨ìˆ˜):** `loss="MSE"`
    * ì˜¤ë¥˜ê°’ì˜ ì •ë„ë¥¼ ê³„ì‚°í•˜ëŠ” **í‰ê·  ì œê³± ì˜¤ì°¨(Mean Squared Error)**ë²• í™œìš©.
* **Compile:** * ì„¤ê³„í•œ ëª¨ë¸ êµ¬ì¡°ì™€ ìµœì í™” ë°©ë²•(SGD), ì†ì‹¤ í•¨ìˆ˜(MSE)ë¥¼ í•˜ë‚˜ë¡œ ë¬¶ì–´ ì»´í“¨í„°ê°€ ê³„ì‚° ê°€ëŠ¥í•œ ìƒíƒœë¡œ ë³€í™˜í•˜ëŠ” ì„ ì–¸ ë‹¨ê³„.

### 3ï¸âƒ£ í•™ìŠµ ë° í‰ê°€ í”„ë¡œì„¸ìŠ¤ (Training & Evaluation)
* **Training (`model.fit`):**
    * **Epochs:** ì „ì²´ í•™ìŠµ ë°ì´í„°ì…‹ì„ í•œ ë²ˆ ë‹¤ í›‘ëŠ” ë‹¨ìœ„.
    * **Task:** 5,000ê°œì˜ ë°ì´í„°ë¥¼ 7:3ìœ¼ë¡œ ë¶„í• í•˜ì—¬ 3,500ê°œì˜ ë°ì´í„°ë¥¼ 100íšŒ ë°˜ë³µ í•™ìŠµ (ì´ 350,000ë²ˆì˜ ì—°ì‚° ìˆ˜í–‰).
* **Evaluation (`model.evaluate`):**
    * í•™ìŠµì— ì“°ì´ì§€ ì•Šì€ 1,500ê°œì˜ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ì‹¤ì œ ì„±ëŠ¥ ì¸¡ì •.
    * **Verbose=1:** í•™ìŠµ/í‰ê°€ ìƒí™©ì„ ì§„í–‰ ë§‰ëŒ€ê¸°(Progress Bar)ë¡œ ì‹¤ì‹œê°„ ìƒì¤‘ê³„í•˜ëŠ” ì˜µì…˜.
* **Validation Logic:** Train Lossì™€ Test Lossì˜ ì°¨ì´ê°€ í¬ì§€ ì•Šì•„ì•¼ ëª¨ë¸ì´ ì•”ê¸°ê°€ ì•„ë‹Œ **'ë§ì…ˆì˜ ì›ë¦¬'**ë¥¼ ê¹¨ìš°ì³¤ë‹¤ê³  íŒë‹¨í•¨ (ê³¼ì í•© ë°©ì§€).

### 4ï¸âƒ£ Final Simulation Result & Test
- **Task:** ë§ì…ˆ ì—°ì‚° í•™ìŠµ ($x_1 + x_2$)
- **Dataset:** `random()/2`ë¥¼ ì‚¬ìš©í•´ í•©ì´ 1ì„ ë„˜ì§€ ì•ŠëŠ” 5,000ê°œì˜ ë°ì´í„° ìƒì„±.
- **Training:** 100 ì—í¬í¬ ë™ì•ˆ ì´ 350,000ë²ˆì˜ í•™ìŠµ ìˆ˜í–‰.
- **Result:** í•œ ë²ˆë„ ë³´ì§€ ëª»í•œ `[[0.1, 0.2], [0.2, 0.2]]`ì™€ ê°™ì€ ë°ì´í„°ë¥¼ ì£¼ì—ˆì„ ë•Œ ì •ë‹µì— ê·¼ì‚¬í•œ ê°’ì„ ì¶œë ¥í•¨.

## 08. Audio Data Preprocessing (STFT & MFCC)
- **Goal:** ì‹œê³„ì—´ ë°ì´í„°ì¸ ì˜¤ë””ì˜¤ë¥¼ AI ëª¨ë¸ì´ í•™ìŠµ ê°€ëŠ¥í•œ 'ì´ë¯¸ì§€' í˜•íƒœì˜ íŠ¹ì§•ëŸ‰(Feature)ìœ¼ë¡œ ë³€í™˜.
- **Process:**
  1. **Load:** ì•„ë‚ ë¡œê·¸ ì‹ í˜¸ë¥¼ ë””ì§€í„¸ ìƒ˜í”Œ ë°°ì—´(`signal`)ë¡œ ë³€í™˜.
  2. **STFT:** ì‹œê°„ì˜ íë¦„ì„ ë°˜ì˜í•˜ê¸° ìœ„í•´ ì‹ í˜¸ë¥¼ ì§§ê²Œ ì˜ë¼ ì£¼íŒŒìˆ˜ ë¶„ì„.
  3. **MFCC:** ì¸ê°„ì˜ ì²­ê° íŠ¹ì„±ì„ ë°˜ì˜í•˜ì—¬ ì†Œë¦¬ì˜ 'ìŒìƒ‰(Timbre)' íŠ¹ì§• ì¶”ì¶œ.

---

### 08.1 Digital Audio Foundation (ADC & SR)
- **Concept:** ì•„ë‚ ë¡œê·¸ ì‹ í˜¸ë¥¼ ì´ˆë‹¹ $sr$(Sampling Rate)ë§Œí¼ ìƒ˜í”Œë§í•˜ì—¬ ì–‘ìí™”(Quantize)í•˜ëŠ” ê³¼ì •.
- **Nyquist Theorem:** íŠ¹ì • ì£¼íŒŒìˆ˜ë¥¼ ë³µì›í•˜ë ¤ë©´ í•´ë‹¹ ì£¼íŒŒìˆ˜ë³´ë‹¤ ìµœì†Œ 2ë°° ì´ìƒì˜ ì†ë„ë¡œ ìƒ˜í”Œë§í•´ì•¼ í•¨. ì¸ê°„ì˜ ê°€ì²­ ì£¼íŒŒìˆ˜(ì•½ 20kHz)ë¥¼ ê³ ë ¤í•˜ì—¬ ë””ì§€í„¸ ìŒì›ì€ ë³´í†µ 44.1kHzë¥¼ ì‚¬ìš©í•˜ë‚˜, ë”¥ëŸ¬ë‹ì—ì„œëŠ” ê³„ì‚° íš¨ìœ¨ì„ ìœ„í•´ `sr=22050`ì„ ì£¼ë¡œ ì‚¬ìš©í•¨.
- **Parameters:** `sr=22050` (1ì´ˆì— 22,050ê°œì˜ ì ì„ ì°ì–´ ì†Œë¦¬ë¥¼ ê¸°ë¡).

### 08.2 Waveform Analysis
- **Definition:** ì‹œê°„ì¶•($x$)ì— ë”°ë¥¸ ì§„í­($y$, Amplitude)ì˜ ë³€í™”ë¥¼ ë‚˜íƒ€ë‚´ëŠ” Raw ë°ì´í„°.
- **Characteristics:**
  - `signal`: ê° ìƒ˜í”Œì˜ ì§„í­ê°’(-1 ~ 1)ì„ ë‹´ì€ 1ì°¨ì› `NumPy` ë°°ì—´.
  - **Data Size:** 30ì´ˆ ìŒì› ê¸°ì¤€ $22050 \times 30 = 661,500$ ê°œì˜ ë°ì´í„° í¬ì¸íŠ¸ë¡œ êµ¬ì„±.
- **Insight:** ì „ì²´ì ì¸ ì†Œë¦¬ì˜ í¬ê¸°(Energy)ì™€ íƒ€ê²©ê°ì€ í™•ì¸í•  ìˆ˜ ìˆìœ¼ë‚˜, ì–´ë–¤ ì£¼íŒŒìˆ˜(ìŒë†’ì´) ì„±ë¶„ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ëŠ” íŒŒì•…í•˜ê¸° ì–´ë ¤ì›€.

#### **ğŸ“Š Waveform Result & Analysis**
![Waveform](./image/262509_blues_1_waveform.png)

### 08.3 Frequency Analysis (FFT & Spectrum)
- **Goal:** ì‹œê°„ ì˜ì—­(Time Domain)ì˜ íŒŒí˜•ì„ ì£¼íŒŒìˆ˜ ì˜ì—­(Frequency Domain)ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì†Œë¦¬ì— ì„ì¸ 'ìŒë†’ì´' ì„±ë¶„ë“¤ì„ ë¶„ì„.
- **Process:**
  1. **np.fft.fft(signal):** ì´ì‚° í‘¸ë¦¬ì— ë³€í™˜ì„ ìˆ˜í–‰í•˜ì—¬ ë³µì†Œìˆ˜ ë°°ì—´ ìƒì„±.
  2. **Magnitude:** ë³µì†Œìˆ˜ì— `np.abs()`ë¥¼ ì·¨í•´ ê° ì£¼íŒŒìˆ˜ ì„±ë¶„ì˜ ì‹¤ì œ ì—ë„ˆì§€ ì„¸ê¸°ë¥¼ ë„ì¶œ.
  3. **Frequency Mapping:** `np.linspace(0, sr, len(magnitude))`ë¥¼ í†µí•´ ì¸ë±ìŠ¤ë¥¼ ì‹¤ì œ ì£¼íŒŒìˆ˜(Hz) ë‹¨ìœ„ë¡œ ëŒ€ì‘.
  4. **Nyquist Symmetry:** ì‹¤ìˆ˜ ì‹ í˜¸ì˜ ëŒ€ì¹­ì„±ì— ë”°ë¼ ì˜ë¯¸ ìˆëŠ” ì–‘ì˜ ì£¼íŒŒìˆ˜ ì˜ì—­($0 \sim 11,025Hz$)ë§Œ ì¶”ì¶œ.

![FFT_Spectrum](./image/262509_blues_1_FFT.png)

#### **ğŸ“Š FFT Result & Analysis**
- **Magnitude Peaks:** ê·¸ë˜í”„ ì¢Œì¸¡(0~2000Hz)ì— ê±°ëŒ€í•œ ì—ë„ˆì§€ í”¼í¬ë“¤ì´ ë°€ì§‘í•´ ìˆìŒ. ì´ëŠ” ë¸”ë£¨ìŠ¤ ìŒì•…ì˜ ë¦¬ë“¬ê³¼ ë¬´ê²Œê°ì„ ë‹´ë‹¹í•˜ëŠ” ë² ì´ìŠ¤ ê¸°íƒ€, ë“œëŸ¼ í‚¥ì˜ ì €ìŒì—­ëŒ€ ì„±ë¶„ì´ ë§¤ìš° ê°•ë ¬í•¨ì„ ì‹œì‚¬í•¨.
- **Frequency Distribution:** 4000Hz ì´í›„ë¡œ ê°ˆìˆ˜ë¡ ì—ë„ˆì§€ê°€ ê¸‰ê²©íˆ ê°ì†Œí•¨. ì´ëŠ” ìŒì•…ì˜ ì£¼ëœ ì •ë³´(ì•…ê¸° ì„ ìœ¨, ë³´ì»¬)ê°€ ì£¼ë¡œ ì €ìŒê³¼ ì¤‘ìŒì—­ëŒ€ì— ì§‘ì¤‘ë˜ì–´ ìˆìŒì„ ë³´ì—¬ì¤Œ.
- **The "Missing Link" (FFTì˜ í•œê³„):** ì£¼íŒŒìˆ˜ ì„±ë¶„ì˜ ë¹„ìœ¨ì€ ëª…í™•íˆ ì•Œ ìˆ˜ ìˆìœ¼ë‚˜, ì´ ' Magnitude'ë“¤ì´ **ì–´ëŠ ì‹œì (When)**ì— íŠ€ì–´ë‚˜ì™”ëŠ”ì§€ëŠ” ì•Œ ìˆ˜ ì—†ìŒ. (30ì´ˆ ì „ì²´ë¥¼ í‰ê·  ë‚¸ ê²°ê³¼ì´ê¸° ë•Œë¬¸)
- **Insight:** ì´ ì‹œê°„ ì •ë³´ì˜ ìƒì‹¤ì„ í•´ê²°í•˜ê¸° ìœ„í•´, ì‹ í˜¸ë¥¼ ì•„ì£¼ ì§§ê²Œ ìª¼ê°œì–´ ë¶„ì„í•˜ëŠ” **STFT(Spectrogram)** ê³¼ì •ì´ í•„ì—°ì ìœ¼ë¡œ ë’¤ë”°ë¼ì•¼ í•¨.


### 08.4 Short-Time Fourier Transform (STFT & Spectrogram)
- **Goal:** FFTì˜ í•œê³„(ì‹œê°„ ì •ë³´ ì†Œì‹¤)ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ ì‹ í˜¸ë¥¼ ì§§ì€ êµ¬ê°„ìœ¼ë¡œ ë‚˜ëˆ„ì–´ 'ì‹œê°„ì— ë”°ë¥¸ ì£¼íŒŒìˆ˜ ë³€í™”'ë¥¼ ë¶„ì„.
- **The Logic (ì§€ìš´ë‹˜ì˜ í†µì°°):**
  - **ë°ìƒì˜ ìŒì˜:** ë³´í­(`hop_length`)ì„ ìœˆë„ìš° í¬ê¸°ë³´ë‹¤ ì‘ê²Œ ì„¤ì •í•˜ì—¬ ê²¹ì¹˜ê²Œ ìŠ¤ìº”í•¨ìœ¼ë¡œì¨, ì—°ì†ì ì¸ ì†Œë¦¬ì˜ ë³€í™”ë¥¼ ë¶€ë“œëŸ¬ìš´ ìŒì˜ì²˜ëŸ¼ ê·¸ë ¤ëƒ„.
  - **3ì°¨ì› ì •ë³´:** ê°€ë¡œì¶•(ì‹œê°„), ì„¸ë¡œì¶•(ì£¼íŒŒìˆ˜), ìƒ‰ìƒ(ì—ë„ˆì§€ ì„¸ê¸°)ìœ¼ë¡œ ì†Œë¦¬ë¥¼ ì‹œê°í™”.

### ğŸ“Š Spectrogram Transformation: Linear vs. Log Scale

| 1. Linear Spectrogram (Before Log) | 2. Log Spectrogram (After Log/dB) |
| :---: | :---: |
| ![Linear Spectrogram](./image/262509_blues_1_linear_spectogram.png) | ![Log Spectrogram](./image/262509_blues_1_spectogram.png) |
| **ë¬¼ë¦¬ì  ì§„í­(Amplitude) ê¸°ë°˜** | **ë°ì‹œë²¨(dB) ìŠ¤ì¼€ì¼ ê¸°ë°˜** |

#### **ğŸ” ê²°ê³¼ ë¹„êµ ë° ë¶„ì„ (Analysis)**

1. **Linear Spectrogram (ë¡œê·¸ ì·¨í•˜ê¸° ì „)**
   - **íŠ¹ì§•:** ì†Œë¦¬ì˜ ë¬¼ë¦¬ì ì¸ ì—ë„ˆì§€ê°€ ì•„ì£¼ í° ë¶€ë¶„(í”¼í¬ ì§€ì )ë§Œ ë°ê²Œ í‘œì‹œë¨.
   - **í•œê³„:** ì¸ê°„ì˜ ê·€ëŠ” ì•„ì£¼ ì‘ì€ ì†Œë¦¬ë¶€í„° í° ì†Œë¦¬ê¹Œì§€ ê´‘ë²”ìœ„í•˜ê²Œ ì¸ì§€í•˜ì§€ë§Œ, ì„ í˜• ê·¸ë˜í”„ì—ì„œëŠ” ì—ë„ˆì§€ê°€ ì¡°ê¸ˆë§Œ ë‚®ì•„ë„ ëª¨ë‘ ê²€ì€ìƒ‰ìœ¼ë¡œ ë¬»í˜€ë²„ë ¤ ì„¸ë°€í•œ ìŒìƒ‰ íŒ¨í„´ì´ë‚˜ ë°°ìŒ êµ¬ì¡°ë¥¼ íŒŒì•…í•˜ê¸° ì–´ë ¤ì›€.

2. **Log Spectrogram (ë¡œê·¸ ì·¨í•œ í›„/dB ë³€í™˜)**
   - **íŠ¹ì§•:** `librosa.amplitude_to_db`ë¥¼ í†µí•´ ì‘ì€ ì—ë„ˆì§€ ë³€í™”ë„ ì‹œê°ì ìœ¼ë¡œ ë“œëŸ¬ë‚˜ê²Œ ë³€í™˜.
   - **ì¥ì :** - **ì¸ê°„ì˜ ì¸ì§€ ë°˜ì˜:** ì¸ê°„ì€ ì†Œë¦¬ì˜ í¬ê¸°ë¥¼ ë¡œê·¸(Log) ë‹¨ìœ„ë¡œ ì¸ì§€í•˜ë¯€ë¡œ, ì‹¤ì œ ìš°ë¦¬ê°€ ê·€ë¡œ ë“£ëŠ” ëŠë‚Œê³¼ ì‹œê°ì  ì •ë³´ê°€ ì¼ì¹˜í•˜ê²Œ ë¨.
     - **ë””í…Œì¼ ë¶€ê°:** ì´ì „ì—ëŠ” ë³´ì´ì§€ ì•Šë˜ ì €ìŒì—­ëŒ€ì˜ ë¯¸ì„¸í•œ ì›€ì§ì„ê³¼ ê³ ìŒì—­ëŒ€ì˜ ë°°ìŒ(Harmonics) êµ¬ì¡°ê°€ ëª…í™•í•˜ê²Œ ë“œëŸ¬ë‚¨.
     - **í•™ìŠµ íš¨ìœ¨:** ë°ì´í„°ì˜ ë²”ìœ„ê°€ ì••ì¶•ë˜ì–´ ë”¥ëŸ¬ë‹ ëª¨ë¸ì´ ì†Œë¦¬ì˜ íŠ¹ì§•ì„ ë” ì•ˆì •ì ìœ¼ë¡œ í•™ìŠµí•  ìˆ˜ ìˆëŠ” ìƒíƒœê°€ ë¨.

### 08.5 Mel-Frequency Cepstral Coefficients (MFCCs)
- **Goal:** ì£¼íŒŒìˆ˜ ì „ì²´ê°€ ì•„ë‹Œ, ì†Œë¦¬ì˜ 'ìŒìƒ‰(Timbre)'ì„ ê²°ì •ì§“ëŠ” í•µì‹¬ ì§€ë¬¸ 13ê°œë¥¼ ì¶”ì¶œ.
- **Concept:** - **Mel Scale:** ì¸ê°„ì˜ ê·€ê°€ ì €ìŒì—­ëŒ€ ë³€í™”ì— ë” ë¯¼ê°í•˜ë‹¤ëŠ” íŠ¹ì„±ì„ ë°˜ì˜í•˜ì—¬ ì£¼íŒŒìˆ˜ ì¶•ì„ ì¬ì¡°ì •.
  - **Feature Compression:** Spectrogramì˜ ë°©ëŒ€í•œ ì •ë³´ë¥¼ 13ê°œì˜ ì¶”ìƒí™”ëœ ê³„ìˆ˜ë¡œ ì••ì¶•í•˜ì—¬ ë”¥ëŸ¬ë‹ ëª¨ë¸ì´ 'ê³µë¶€í•˜ê¸° ì¢‹ì€ ìš”ì•½ë³¸'ì„ ì œê³µ.

![MFCC](./image/262509_blues_1_MFCCs.png)

#### **ğŸ“Š MFCC Result & Analysis**
- **Feature Extraction:** ì•½ 66ë§Œ ê°œì˜ ìƒ˜í”Œ ë°ì´í„°ë¥¼ ë‹¨ 13ê°œì˜ íŠ¹ì§• ì—´ë¡œ ì••ì¶•í•¨ì—ë„ ë¶ˆêµ¬í•˜ê³ , ìŒì›ì˜ ê³ ìœ í•œ ì •ì²´ì„±ì€ ìœ ì§€ë¨.
- **Interpretation:** - ë§¨ ì•„ë˜ìª½ ë¶‰ì€ìƒ‰ ë (0ë²ˆ ê³„ìˆ˜)ëŠ” ìŒì›ì˜ **ì „ì²´ì ì¸ ì—ë„ˆì§€ íë¦„**ì„ ë‚˜íƒ€ëƒ„.
  - ìƒë‹¨ì˜ 1~12ë²ˆ ê³„ìˆ˜ë“¤ì€ **ì†Œë¦¬ì˜ ì§ˆê° íŒ¨í„´**ì„ ë‹´ê³  ìˆìœ¼ë©°, ê°€ë¡œë¡œ ì´ì–´ì§€ëŠ” ìƒ‰ìƒì˜ ë³€í™”ê°€ ê³§ ì´ ë¸”ë£¨ìŠ¤ ìŒì•…ì˜ 'ìŒìƒ‰ì  ì§€ë¬¸'ì„.
- **Final Insight:** AI ëª¨ë¸ì€ ì´ì œ ì´ 13ê°€ì§€ ì„±ë¶„ì˜ ì‹œê³„ì—´ ë³€í™”ë¥¼ í•™ìŠµí•˜ì—¬, ìƒˆë¡œìš´ ì†Œë¦¬ê°€ ë“¤ë ¸ì„ ë•Œ ê·¸ê²ƒì´ 'ë¸”ë£¨ìŠ¤'ì¸ì§€ 'ì¬ì¦ˆ'ì¸ì§€ íŒë³„í•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì„ ê°–ì¶”ê²Œ ë¨.

## 09. Audio Data Preprocessing (STFT & MFCC) Pipeline

### 09.1 ë°ì´í„° ì €ì¥ ë°©ì‹ì˜ ì „ëµ (ì™œ JSONì¸ê°€?)

#### 1) Raw Data ëŒ€ë¹„ íšê¸°ì ì¸ ìš©ëŸ‰ ë‹¤ì´ì–´íŠ¸
* **ê¸°ì¡´ ë¬¸ì œ**: `.wav` íŒŒì¼ì€ `Sample Rate(22050) Ã— ì‹œê°„(30ì´ˆ)` ë§Œí¼ì˜ ë°ì´í„°ë¥¼ ê°€ì§. 1ê³¡ë‹¹ ì•½ 66ë§Œ ê°œì˜ ìƒ˜í”Œì„ ì‹¤ì‹œê°„ ì—°ì‚°í•˜ê¸°ì—” í•˜ë“œì›¨ì–´ ë¶€ë‹´ì´ ë„ˆë¬´ í¼.
* **í•´ê²°ì±…**: ì˜¤ë””ì˜¤ íŒŒí˜•(Waveform) ì „ì²´ë¥¼ ë“¤ê³  ê°€ëŠ” ê²Œ ì•„ë‹ˆë¼, í•™ìŠµì— í•„ìš”í•œ **ìŒìƒ‰ ì§€ë¬¸(MFCC)**ë§Œ ì¶”ì¶œí•´ ì €ì¥í•¨. 
* **ê²°ê³¼**: ìˆ˜ì²œ ê°œì˜ ê³ ìš©ëŸ‰ ìŒì›ì„ ì§ì ‘ ë¡œë“œí•  í•„ìš” ì—†ì´, ì´ë¯¸ ê³„ì‚°ì´ ëë‚œ ìˆ«ì ë¦¬ìŠ¤íŠ¸(JSON)ë§Œ ì½ì–´ì˜¤ë©´ ë˜ë¯€ë¡œ ë°ì´í„° ë¡œë”© ì†ë„ê°€ ë¹„ì•½ì ìœ¼ë¡œ ìƒìŠ¹í•¨.

#### 2) JSON í˜•ì‹ì„ í†µí•œ ë°ì´í„° êµ¬ì¡°ì˜ ìœ ì—°ì„±(ê°€ë³€ì„±)
* **ì»¤ìŠ¤í…€ ì„¤ê³„**: JSONì€ ê³ ì •ëœ í˜•ì‹ì´ ì•„ë‹˜. ìš°ë¦¬ê°€ ì„¤ê³„í•œ `mapping`, `mfcc`, `labels`ë¼ëŠ” êµ¬ì¡° ì•ˆì— í•„ìš”í•œ ì •ë³´ë¥¼ ì„ íƒì ìœ¼ë¡œ ë‹´ì„ ìˆ˜ ìˆìŒ.
* **ê³µìœ  ë° ê°€ë…ì„±**: ë°”ì´ë„ˆë¦¬ í˜•íƒœì˜ ë°ì´í„°ë³´ë‹¤ ì‚¬ëŒì´ êµ¬ì¡°ë¥¼ íŒŒì•…í•˜ê¸° ì‰½ê³ , Pythonì˜ Dictionaryì™€ 1:1 ëŒ€ì‘ë˜ì–´ ëª¨ë¸ í•™ìŠµ ì‹œ ë°ì´í„°ë¥¼ ê³µê¸‰í•˜ëŠ” íŒŒì´í”„ë¼ì¸ êµ¬ì¶•ì´ ë§¤ìš° ìš©ì´í•¨.

#### 3) MFCC 13ê°œ: ì†Œë¦¬ì˜ 'í•µì‹¬ ìš”ì•½ë³¸' ì „ëµ
* **ë°ì´í„° ì••ì¶•**: ì£¼íŒŒìˆ˜ ì „ì²´ ì„±ë¶„ì„ ë‹¤ ì €ì¥í•˜ë©´ ì •ë³´ëŸ‰ì´ ì—¬ì „íˆ ë°©ëŒ€í•¨. í•˜ì§€ë§Œ ì¸ê°„ì˜ ì²­ê° íŠ¹ì„±ì„ ë°˜ì˜í•œ **MFCC 13ê°œ**ë§Œìœ¼ë¡œë„ í•´ë‹¹ ì¥ë¥´ì˜ ìŒìƒ‰ì  íŠ¹ì§•ì„ ì¶©ë¶„íˆ í‘œí˜„ ê°€ëŠ¥í•¨.
* **í•™ìŠµ ì •í™•ë„ í–¥ìƒ**: ë¶ˆí•„ìš”í•œ ê³ ì£¼íŒŒ ë…¸ì´ì¦ˆë‚˜ ì„¸ì„¸í•œ ì •ë³´ë¥¼ ë²„ë¦¬ê³ , ì¥ë¥´ ë¶„ë¥˜ì— í•µì‹¬ì ì¸ **'ìŒìƒ‰ì˜ íŒ¨í„´'**ë§Œ ë‚¨ê¹€ìœ¼ë¡œì¨ ëª¨ë¸ì´ ë°ì´í„°ì— í¬í•¨ëœ ë…¸ì´ì¦ˆ ëŒ€ì‹  ë³¸ì§ˆì ì¸ íŠ¹ì§•ì— ì§‘ì¤‘í•˜ê²Œ ë§Œë“¦.

#### 4) FFT ê¸°ë°˜ ì£¼íŒŒìˆ˜ ì €ì¥ ë°©ì‹ê³¼ì˜ ë¹„êµ
* **FFT ë°©ì‹**: ë‹¨ìˆœíˆ ëª¨ë“  ì£¼íŒŒìˆ˜ ì„±ë¶„ì„ ì €ì¥í•˜ë©´ ì‹œì ë§ˆë‹¤ ìˆ˜ì²œ ê°œì˜ ë°ì´í„° í¬ì¸íŠ¸ê°€ ë°œìƒí•˜ì—¬ JSON êµ¬ì¡°ê°€ ì§€ë‚˜ì¹˜ê²Œ ë°©ëŒ€í•´ì§€ê³  ë³µì¡í•´ì§.
* **MFCC ë°©ì‹**: FFT ê²°ê³¼ì— Mel-filter bankì™€ ë¡œê·¸ ì—°ì‚° ë“±ì„ ì¶”ê°€í•˜ì—¬ ì •ë³´ë¥¼ 13ê°œì˜ ê³„ìˆ˜ë¡œ ì••ì¶•í•¨. ê²°ê³¼ì ìœ¼ë¡œ **ì»´í“¨í„°ì˜ ì—°ì‚° ë¶€ë‹´ì€ ìµœì†Œí™”**í•˜ë©´ì„œë„ **í•™ìŠµ íš¨ìœ¨ì€ ê·¹ëŒ€í™”**í•˜ëŠ” ìµœì ì˜ ë°¸ëŸ°ìŠ¤ë¥¼ ì°¾ì€ ê²°ê³¼ì„.

### 09.2 Dictionary êµ¬ì¡°ì™€ ë°ì´í„° ë§¤ì¹­ ì›ë¦¬ (Data Simulation)

#### 1) ë”•ì…”ë„ˆë¦¬ì˜ êµ¬ì„± ìš”ì†Œì™€ ì—­í• 
ì¶”ì¶œëœ ë°ì´í„°ëŠ” `mapping`, `mfcc`, `labels`ë¼ëŠ” ì„¸ ê°€ì§€ í•µì‹¬ ì—´ì‡ (Key)ë¡œ ê´€ë¦¬ë˜ë©°, ì´ëŠ” ëª¨ë¸ì´ í•™ìŠµí•  'êµê³¼ì„œ'ì˜ ëª©ì°¨, ë³¸ë¬¸, ì •ë‹µì§€ì™€ ê°™ìŒ.

* **`mapping` (ì¥ë¥´ ì´ë¦„í‘œ)**: ìˆ«ìë¡œ ë°”ë€ ì¥ë¥´ ë²ˆí˜¸ê°€ ì‹¤ì œ ì–´ë–¤ ì¥ë¥´(ì˜ˆ: "hiphop", "blues")ì¸ì§€ ì•Œë ¤ì£¼ëŠ” ë²ˆì—­ê¸°ì„. ë¦¬ìŠ¤íŠ¸ì˜ ì¸ë±ìŠ¤ ë²ˆí˜¸ê°€ ê³§ ì¥ë¥´ì˜ IDê°€ ë¨.
* **`mfcc` (ë°ì´í„° ë³¸ì²´)**: ëª¨ë¸ì´ íŒ¨í„´ì„ ì½ì–´ë‚´ì•¼ í•  ì‹¤ì œ ìˆ«ì ì§€ë„ì„. 3ì°¨ì› ë°°ì—´ êµ¬ì¡°ë¡œ ì´ë£¨ì–´ì ¸ ìˆìœ¼ë©°, í•™ìŠµì— í•„ìš”í•œ ëª¨ë“  ì†Œë¦¬ì˜ ì§€ë¬¸ì´ ë‹´ê¹€.
* **`labels` (ì •ë‹µ ë²ˆí˜¸)**: ê° MFCC ë©ì–´ë¦¬ê°€ ì–´ë–¤ ì¥ë¥´ì¸ì§€ ì•Œë ¤ì£¼ëŠ” ì •ë‹µì§€ì„. `mapping` ë¦¬ìŠ¤íŠ¸ì˜ ì¸ë±ìŠ¤ ë²ˆí˜¸ë¥¼ ì €ì¥í•˜ì—¬ ë¬¸ì œ(MFCC)ì™€ ì •ë‹µ(Label)ì„ 1:1ë¡œ ë§¤ì¹­í•¨.

#### 2) `mfcc` 3ì°¨ì› ë°°ì—´ì˜ ì •ë°€ êµ¬ì¡° (5 Ã— 258 Ã— 13)
ë°ì´í„°ê°€ ì €ì¥ë˜ëŠ” ê¹Šì´ë¥¼ ì‹œë®¬ë ˆì´ì…˜í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì€ ì²´ê³„ì ì¸ êµ¬ì¡°ë¥¼ ê°€ì§.

* **1ë‹¨ê³„ (ì´ 5ê°œì˜ ê¾¸ëŸ¬ë¯¸)**: 30ì´ˆ ë…¸ë˜ë¥¼ 5ë“±ë¶„ í–ˆìœ¼ë¯€ë¡œ, í•œ ê³¡ë‹¹ 6ì´ˆì§œë¦¬ MFCC ë©ì–´ë¦¬ê°€ 5ê°œ ìƒì„±ë¨.
* **2ë‹¨ê³„ (ì•½ 258ê°œì˜ ì‹œê°„ ì¤„)**: 6ì´ˆì˜ ì¡°ê°ì„ `hop_length(512)` ë‹¨ìœ„ë¡œ ìª¼ê°œì–´ ë¶„ì„í•œ ê²°ê³¼ë¬¼ì„. (ì•½ 6ì´ˆ Ã— 22050Hz / 512 â‰ˆ 258ì¤„)
* **3ë‹¨ê³„ (13ê°œì˜ ì‹¤ìˆ˜ ê°’)**: ê° ì‹œê°„ ì¤„ë§ˆë‹¤ ì¶”ì¶œëœ ì†Œë¦¬ì˜ í•µì‹¬ íŠ¹ì§•(MFCC ê³„ìˆ˜)ë“¤ì„. ì´ 13ê°œì˜ ìˆ«ìê°€ ëª¨ì—¬ í•´ë‹¹ ì‹œì ì˜ 'ìŒìƒ‰'ì„ ê²°ì •í•¨.

#### 3) ë°ì´í„° ì €ì¥ ìƒíƒœ ì‹œë®¬ë ˆì´ì…˜ (hiphop.00004.wav ì²˜ë¦¬ ì˜ˆì‹œ)
ì‹¤ì œ ë°ì´í„°ê°€ ë”•ì…”ë„ˆë¦¬ì— ëˆ„ì ë˜ëŠ” ê³¼ì •ì„ ì‹œê°í™”í•˜ë©´ ë‹¤ìŒê³¼ ê°™ìŒ.

```python
data = {
    # 1. mapping: ì¸ë±ìŠ¤ ë²ˆí˜¸ì™€ ì¥ë¥´ëª…ì„ ë§¤ì¹­ (2ë²ˆ ì¸ë±ìŠ¤ = "hiphop")
    "mapping": ["classical", "blues", "hiphop"],

    # 2. mfcc: 1ê³¡(30ì´ˆ)ì„ 5ë“±ë¶„(6ì´ˆì”©)í•˜ì—¬ ì¶”ì¶œëœ ìˆ«ì ì§€ë„ë“¤
    # ê° ì¡°ê°ì€ [258(ì‹œê°„) x 13(ìŒìƒ‰)]ì˜ í–‰ë ¬ êµ¬ì¡°ë¥¼ ê°€ì§
    "mfcc": [
        [[...], [...], ...], # 1ë²ˆì§¸ 6ì´ˆ êµ¬ê°„ (MFCC í–‰ë ¬)
        [[...], [...], ...], # 2ë²ˆì§¸ 6ì´ˆ êµ¬ê°„ (MFCC í–‰ë ¬)
        [[...], [...], ...], # 3ë²ˆì§¸ 6ì´ˆ êµ¬ê°„ (MFCC í–‰ë ¬)
        [[...], [...], ...], # 4ë²ˆì§¸ 6ì´ˆ êµ¬ê°„ (MFCC í–‰ë ¬)
        [[...], [...], ...]  # 5ë²ˆì§¸ 6ì´ˆ êµ¬ê°„ (MFCC í–‰ë ¬)
    ],

    # 3. labels: ìœ„ 5ê°œ ë©ì–´ë¦¬ê°€ ëª¨ë‘ 'hiphop(2ë²ˆ)'ì„ì„ ì¦ëª…í•˜ëŠ” ì •ë‹µ ë²ˆí˜¸
    "labels": [2, 2, 2, 2, 2] 
}
```
### 09.3 ì „ì²˜ë¦¬ ê³µì •ì˜ ìë™í™”ì™€ ê·œê²©í™” ë¡œì§ (Algorithm & Safety)

#### 1) 3ì¤‘ ë°˜ë³µë¬¸ê³¼ 'ìš°ì²´ë¶€' ë©”ì»¤ë‹ˆì¦˜ (`os.walk`)
`os.walk` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ì…‹ í´ë”ì˜ ê°€ì¥ ê¹Šì€ ê³³ê¹Œì§€ íŒŒê³ ë“¤ë©° ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•¨.
* **í´ë” íƒìƒ‰ ì „ëµ**: `Data/genres/`ë¥¼ ì‹œì‘ì ìœ¼ë¡œ ì¡ìœ¼ë©´ í•˜ìœ„ í´ë”(blues, hiphop ë“±)ë¥¼ í•˜ë‚˜ì”© ë°©ë¬¸í•¨. 
* **ì£¼ì˜ì‚¬í•­**: í•˜ìœ„ í´ë” êµ¬ì¡°ê°€ ì¤‘ì²©ë˜ë©´(ì˜ˆ: `music/jazz/`) ì‹œìŠ¤í…œì´ 'music' ìì²´ë¥¼ ì¥ë¥´ë¡œ ì˜¤í•´í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ë°ì´í„°ì…‹ì€ í•­ìƒ `ì¥ë¥´ëª…/íŒŒì¼ë“¤`ì˜ ë‹¨ì¼ ê³„ì¸µ êµ¬ì¡°ë¥¼ ìœ ì§€í•´ì•¼ í•¨.
* **filenamesì˜ ì˜ë¯¸**: ìš°ì²´ë¶€ê°€ íŠ¹ì • ì¥ë¥´ í´ë”ì— ë„ì°©í–ˆì„ ë•Œ, ê·¸ ì•ˆì— ë“¤ì–´ìˆëŠ” ê°œë³„ ìŒì› íŒŒì¼ë“¤ì˜ ëª©ë¡ì„ ì˜ë¯¸í•¨.

#### 2) ì„¸ê·¸ë¨¼íŠ¸ë‹¹ ìƒ˜í”Œ ê³„ì‚° (`num_samples_per_segment`)
* **ê°œë…**: íŠ¸ë™ë‹¹ ì´ ìƒ˜í”Œ ìˆ˜(`SAMPLE_PER_TRACK`)ë¥¼ `num_segments(5)`ë¡œ ë‚˜ëˆˆ ê°’ì„.
* **ìˆ˜ì¹˜**: 30ì´ˆ ìŒì› ê¸°ì¤€, 6ì´ˆì˜ ì„¸ê·¸ë¨¼íŠ¸ë‹¹ ì•½ 132,300ê°œì˜ ìƒ˜í”Œ ë°ì´í„°ê°€ ì¡´ì¬í•¨ì„ ì •ì˜í•¨.

#### 3) ë°ì´í„° ê·œê²©í™”ë¥¼ ìœ„í•œ ì•ˆì „ì¥ì¹˜ (`expected_num_mfcc_vectors`)
ë”¥ëŸ¬ë‹ ëª¨ë¸ì€ ì…ë ¥ ë°ì´í„°ì˜ í¬ê¸°ê°€ ëª¨ë‘ **ì¹¼ê°™ì´ ë™ì¼**í•´ì•¼ í•¨. ì´ë¥¼ ìœ„í•´ ë‘ ê°€ì§€ ì¥ì¹˜ë¥¼ ë‘ .

* **ê°€ë¡œì¤„ ê°œìˆ˜ì˜ ê³ ì • (ì˜¬ë¦¼ ì²˜ë¦¬)**: 6ì´ˆ ì¡°ê°ì„ ë¶„ì„í•  ë•Œ `math.ceil`ì„ ì‚¬ìš©í•˜ì—¬ ì•½ 258ê°œì˜ ê°€ë¡œì¤„(MFCC ë²¡í„°)ì´ ìƒê¸°ë„ë¡ ê°•ì œí•¨. ìŒì›ì´ ì•„ì£¼ ë¯¸ì„¸í•˜ê²Œ ì§§ë”ë¼ë„ ë™ì¼í•œ í¬ê¸°ì˜ í–‰ë ¬ì„ ë§Œë“¤ê¸° ìœ„í•¨ì„.
* **ìƒí•œì„  ì œì–´ (`finish_sample`)**: ë¶„ì„ ë²”ìœ„ê°€ 258ê°œë¥¼ ë„˜ì–´ê°€ì§€ ì•Šë„ë¡ ë ì§€ì ì„ ë¯¸ë¦¬ ê³„ì‚°í•´ì„œ ì˜ë¼ë†“ìŒ. ë•ë¶„ì— ëª¨ë“  ì„¸ê·¸ë¨¼íŠ¸ëŠ” **[258 Ã— 13]**ì´ë¼ëŠ” ì™„ë²½í•œ ê·œê²©ì˜ í–‰ë ¬ë¡œ íƒ„ìƒí•¨.

#### 4) ë¶ˆëŸ‰ ì¡°ê° ê²€ìˆ˜ ë¡œì§
ëª¨ë“  ê³„ì‚°ì„ ë§ˆì¹œ í›„, ìµœì¢… ì¶”ì¶œëœ MFCCì˜ ê¸¸ì´ê°€ `expected_num_mfcc_vectors`ì™€ ì¼ì¹˜í•˜ëŠ”ì§€ í•œ ë²ˆ ë” í™•ì¸(`if len(mfcc) == ...`)í•¨. 
* **ì´ìœ **: 0.1ì´ˆë¼ë„ ëª¨ìë€ 'ê·œê²© ë¯¸ë‹¬' ì¡°ê°ì´ í•™ìŠµ ë°ì´í„°ì— ì„ì—¬ ë“¤ì–´ê°€ëŠ” ìˆœê°„, ì „ì²´ ëª¨ë¸ í•™ìŠµì´ ì—ëŸ¬ë¡œ ë©ˆì¶”ëŠ” ê²ƒì„ ë°©ì§€í•˜ê¸° ìœ„í•¨ì„.

### 09.4 ë°ì´í„°ì…‹ êµ¬ì¶•ì˜ í•µì‹¬ ì•Œê³ ë¦¬ì¦˜ (3ì¤‘ Loop & Data Mapping)

#### 1) 3ì¤‘ ë°˜ë³µë¬¸ êµ¬ì¡°ì˜ ì„¤ê³„ ì˜ë„
ì „ì²´ ê³µì •ì€ **ì¥ë¥´ -> íŒŒì¼ -> ì„¸ê·¸ë¨¼íŠ¸** ìˆœìœ¼ë¡œ íŒŒê³ ë“œëŠ” ì²´ê³„ì ì¸ ê³„ì¸µ êµ¬ì¡°ë¡œ ì‘ë™í•¨.

* **1ë‹¨ê³„: `os.walk` (ì¥ë¥´ íƒìƒ‰)**: `dataset_path`ë¶€í„° í•˜ìœ„ í´ë”ê¹Œì§€ íŒŒê³ ë“¦. `i=0`ì€ ìµœìƒìœ„ í´ë”ì´ë¯€ë¡œ ì œì™¸í•˜ê³ , ì„¸ë¶€ ì¥ë¥´(blues, hiphop ë“±)ê°€ ì‹œì‘ë˜ëŠ” ì‹œì ë¶€í„° `i-1`ì„ ì¸ë±ìŠ¤ë¡œ í™œìš©í•´ ì¥ë¥´ë³„ ìˆ«ì IDë¥¼ ë¶€ì—¬í•¨.
* **2ë‹¨ê³„: `filenames` (íŒŒì¼ í˜¸ì¶œ)**: ê° ì¥ë¥´ í´ë” ë‚´ì˜ ìŒì› íŒŒì¼ì„ í•˜ë‚˜ì”© ë¡œë“œí•¨. `os.path.join`ì„ í†µí•´ ìœˆë„ìš°/ë¦¬ëˆ…ìŠ¤ í™˜ê²½ì— êµ¬ì• ë°›ì§€ ì•ŠëŠ” í‘œì¤€ ê²½ë¡œë¥¼ ìƒì„±í•˜ì—¬ íŒŒì¼ì„ ë¶ˆëŸ¬ì˜´.
* **3ë‹¨ê³„: `num_segments` (ë°ì´í„° ë»¥íŠ€ê¸°)**: 30ì´ˆ ìŒì›ì„ 10ê°œ(ì„¤ì •ì— ë”°ë¼ ë‹¤ë¦„)ì˜ ì¡°ê°ìœ¼ë¡œ ë‚˜ëˆ”. `start`ì™€ `finish` ìƒ˜í”Œ ìœ„ì¹˜ë¥¼ ê³„ì‚°í•´ í•˜ë‚˜ì˜ ìŒì›ì—ì„œ ì—¬ëŸ¬ ê°œì˜ í•™ìŠµìš© MFCCë¥¼ ì¶”ì¶œ, ë°ì´í„° ì–‘ì„ íšê¸°ì ìœ¼ë¡œ ëŠ˜ë¦¼.



#### 2) MFCC ì¶”ì¶œ ë° ê·œê²© ê²€ìˆ˜ (Safety Guard)
* **Transpose (`.T`)**: `librosa`ì—ì„œ ì¶”ì¶œëœ ê¸°ë³¸ MFCCëŠ” [13 Ã— 258] êµ¬ì¡°ì„. í•˜ì§€ë§Œ ë”¥ëŸ¬ë‹ ëª¨ë¸ì— ì…ë ¥í•˜ê¸° ìœ„í•´ì„  ì‹œê°„ ì¶•ì„ ê¸°ì¤€ìœ¼ë¡œ í•œ [258 Ã— 13] êµ¬ì¡°ê°€ í•„ìš”í•˜ë¯€ë¡œ í–‰ë ¬ì„ ë’¤ì§‘ì–´ì¤Œ.
* **ì—„ê²©í•œ ê·œê²© í™•ì¸**: `math.ceil`ë¡œ ê³„ì‚°ëœ `expected_num_mfcc_vectors`ì™€ ì‹¤ì œ ì¶”ì¶œëœ ê¸¸ì´ë¥¼ ë¹„êµí•¨. ë‹¨ í•˜ë‚˜ì˜ ìƒ˜í”Œì´ë¼ë„ ëª¨ìë€ ì¡°ê°ì€ `data["mfcc"]`ì— ë‹´ì§€ ì•Šê³  ê³¼ê°íˆ ë²„ë¦¼ìœ¼ë¡œì¨ ë°ì´í„°ì…‹ì˜ ë¬´ê²°ì„±ì„ ìœ ì§€í•¨.

#### 3) JSON ë°ì´í„° ë°”ì¸ë”© ì‹œë®¬ë ˆì´ì…˜
ìµœì¢…ì ìœ¼ë¡œ `data` ë”•ì…”ë„ˆë¦¬ì— ì €ì¥ë˜ëŠ” ë…¼ë¦¬ëŠ” ë‹¤ìŒê³¼ ê°™ìŒ.

* **ë¬¸ì œì§€ (`mfcc`)**: 258ê°œì˜ ê°€ë¡œì¤„(ì‹œê°„)ê³¼ 13ê°œì˜ ì„¸ë¡œì¤„(ìŒìƒ‰ íŠ¹ì§•)ì„ ê°€ì§„ ë¦¬ìŠ¤íŠ¸ê°€ ì°¨ê³¡ì°¨ê³¡ ìŒ“ì„. (Numpy ë°°ì—´ì€ ì €ì¥ì´ ì•ˆ ë˜ë¯€ë¡œ `.tolist()`ë¡œ ë³€í™˜)
* **ì •ë‹µì§€ (`labels`)**: ë§Œì•½ 2ë²ˆ í´ë”ê°€ í™í•©ì´ë¼ë©´, ê·¸ ì•ˆì˜ ëª¨ë“  íŒŒì¼ì—ì„œ ë‚˜ì˜¨ ëª¨ë“  ì„¸ê·¸ë¨¼íŠ¸ì— ëŒ€í•´ `labels.append(2)`ë¥¼ ìˆ˜í–‰í•¨. 
* **ì—°ê²° ê³ ë¦¬**: `mapping[2]`ëŠ” "hiphop", `labels`ì˜ ê°’ì€ `2`. ëª¨ë¸ì€ ì´ë¥¼ í†µí•´ "ì•„, ì´ 258Ã—13 í–‰ë ¬ íŒ¨í„´ì€ í™í•©ì´êµ¬ë‚˜!"ë¼ê³  í•™ìŠµí•˜ê²Œ ë¨.

#### 4) ìµœì¢… ì €ì¥ ë° ê²°ê³¼ (`json.dump`)
* ëª¨ë“  ë£¨í”„ê°€ ì¢…ë£Œë˜ë©´ ìŒ“ì¸ `data` ë”•ì…”ë„ˆë¦¬ë¥¼ `json_path`ì— íŒŒì¼ë¡œ ê¸°ë¡í•¨.
* `indent=4` ì˜µì…˜ì„ ì£¼ì–´ ì‚¬ëŒë„ ëˆˆìœ¼ë¡œ êµ¬ì¡°ë¥¼ ì‰½ê²Œ íŒŒì•…í•  ìˆ˜ ìˆë„ë¡ ë“¤ì—¬ì“°ê¸° ëœ ê¹”ë”í•œ JSON íŒŒì¼ì„ ìƒì„±í•¨.


## 10. Multi-Layer Perceptron (MLP) for Genre Classification

ê¸°ì¡´ì˜ ë§ì…ˆ ì—°ì‚°(MLP_TF)ì„ ë„˜ì–´, ì „ì²˜ë¦¬ëœ ì˜¤ë””ì˜¤ íŠ¹ì§•ëŸ‰(MFCC)ì„ ê¸°ë°˜ìœ¼ë¡œ 10ê°€ì§€ ìŒì•… ì¥ë¥´ë¥¼ ë¶„ë¥˜í•˜ëŠ” ì‹¬ì¸µ ì‹ ê²½ë§ ëª¨ë¸ì„ êµ¬í˜„í•˜ê³  í•™ìŠµ í”„ë¡œì„¸ìŠ¤ë¥¼ ìµœì í™”í•˜ì˜€ìŠµë‹ˆë‹¤.

### 10.1 ëª¨ë¸ ì•„í‚¤í…ì²˜ ëª…ì„¸ (Model Summary)

TensorFlowì˜ `model.summary()` í•¨ìˆ˜ë¥¼ í†µí•´ í™•ì¸í•œ ëª¨ë¸ì˜ ê³„ì¸µ êµ¬ì¡°ì™€ íŒŒë¼ë¯¸í„° ë°°ì • í˜„í™©ì…ë‹ˆë‹¤. ì•½ 100ë§Œ ê°œì˜ í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„°ê°€ ê° ì¸µì— ë°°ë¶„ë˜ì–´ ìˆìŒ.

```text
Model: "sequential"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)                         â”ƒ Output Shape                â”ƒ         Param # â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ flatten (Flatten)                    â”‚ (None, 1690)                â”‚               0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense (Dense)                        â”‚ (None, 512)                 â”‚         865,792 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_1 (Dense)                      â”‚ (None, 256)                 â”‚         131,328 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_2 (Dense)                      â”‚ (None, 64)                  â”‚          16,448 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_3 (Dense)                      â”‚ (None, 10)                  â”‚             650 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 1,014,218 (3.87 MB)
 Trainable params: 1,014,218 (3.87 MB)
 Non-trainable params: 0 (0.00 B)
```

 ### 10.2 ì£¼ìš” ë ˆì´ì–´ ì„¤ê³„ ë° ì—°ì‚° ë¡œì§
* **Flatten Layer (ì…ë ¥ ê·œê²©í™”):**
    * **Output Shape (1690):** 2ì°¨ì› MFCC í–‰ë ¬(130 x 13)ì„ 1,690ê°œì˜ ì›ì†Œë¥¼ ê°€ì§„ 1ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜í•œ ê²°ê³¼.
    * **Param # (0):** ë°ì´í„°ì˜ í˜•íƒœë§Œ ë³€ê²½í•˜ëŠ” ì¸µì´ë¯€ë¡œ ë³„ë„ì˜ í•™ìŠµ íŒŒë¼ë¯¸í„°ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ.
* **Dense Layers (ê°€ì¤‘ì¹˜ ì—°ì‚°):**
    * **Param # ê³„ì‚°:** ì´ì „ ì¸µì˜ ë…¸ë“œ ìˆ˜ì™€ í˜„ì¬ ì¸µì˜ ë…¸ë“œ ìˆ˜ì˜ ê³±ì— í¸í–¥(Bias) ê°’ì„ ë”í•˜ì—¬ ê²°ì •ë©ë‹ˆë‹¤. (ì˜ˆ: dense ì¸µì€ $1,690 \times 512 + 512 = 865,792$ê°œì˜ íŒŒë¼ë¯¸í„°ë¥¼ ê°€ì§)
    * **Activation (ReLU):** ì€ë‹‰ì¸µ ì „ì²´ì— ì ìš©ë˜ì–´ **ê¸°ìš¸ê¸° ì†Œì‹¤(Vanishing Gradient)**ì„ ë°©ì§€í•˜ê³  ë¹„ì„ í˜• íŠ¹ì§• ì¶”ì¶œì„ ê·¹ëŒ€í™”.
* **Output Layer (Softmax):**
    * 10ê°œ ì¥ë¥´ì— ëŒ€í•œ í™•ë¥  ë¶„í¬ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ê°€ì¥ ë†’ì€ í™•ë¥ ê°’ì„ ê°€ì§„ ì¸ë±ìŠ¤ë¥¼ np.argmax()ë¥¼ í†µí•´ ìµœì¢… ë ˆì´ë¸”ë¡œ ì±„íƒ.

### 10.3 í•™ìŠµ ì „ëµ (Compilation)
* **Optimizer: Adam (Learning Rate: 0.0001)**
    * Momentumê³¼ RMSPropì´ ê²°í•©ëœ ì ì‘í˜• ìµœì í™” ë„êµ¬ì…ë‹ˆë‹¤. 0.0001ì˜ ì‹ ì¤‘í•œ í•™ìŠµë¥ ì„ ì ìš©í•˜ì—¬ ë³µì¡í•œ ì†ì‹¤ í•¨ìˆ˜ í‰ë©´ì—ì„œ ì•ˆì •ì ìœ¼ë¡œ ìµœì €ì ì„ ì°¾ì•„ê°€ë„ë¡ í•¨.
* **Loss Function: Sparse Categorical Crossentropy**
    * ëª¨ë¸ì´ ì˜ˆì¸¡í•œ í™•ë¥  ë¶„í¬ì™€ ì‹¤ì œ ì •ìˆ˜í˜• ì •ë‹µ ì‚¬ì´ì˜ ì˜¤ì°¨ë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤. ì˜¤ì°¨ê°€ í´ìˆ˜ë¡ ë†’ì€ í˜ë„í‹°ë¥¼ ë¶€ì—¬í•˜ì—¬ ê°€ì¤‘ì¹˜ ìˆ˜ì •ì„ ìœ ë„.
* **Mini-batch Training (Batch Size: 32)**
    * 32ê°œ ìƒ˜í”Œ ë‹¨ìœ„ë¡œ ê°€ì¤‘ì¹˜ë¥¼ ì—…ë°ì´íŠ¸í•˜ì—¬ ì—°ì‚° íš¨ìœ¨ì„±ê³¼ í•™ìŠµ ì•ˆì •ì„±ì˜ ê· í˜•ì„ ë§ì¶¤.

### 10.4 ê²°ê³¼ ë¶„ì„: ê³¼ì í•©(Overfitting) ì§„ë‹¨
* **ì„±ëŠ¥ ë¶ˆê· í˜•:** í›ˆë ¨ ì •í™•ë„(95%)ì— ë¹„í•´ ê²€ì¦ ì •í™•ë„(59%)ê°€ í˜„ì €íˆ ë‚®ê²Œ ë‚˜íƒ€ë‚¨.
![Overfitting](./image/260212_overfitting.png)
* **ì§„ë‹¨ ê²°ê³¼:** ëª¨ë¸ì˜ ë†’ì€ ë³µì¡ë„(100ë§Œ íŒŒë¼ë¯¸í„°)ì— ë¹„í•´ í•™ìŠµ ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬, ë°ì´í„°ì˜ ì¼ë°˜ì ì¸ íŒ¨í„´ì´ ì•„ë‹Œ ê°œë³„ ìƒ˜í”Œì˜ íŠ¹ì´ì¹˜(ë…¸ì´ì¦ˆ)ë¥¼ ì•”ê¸°í•´ë²„ë¦° ì „í˜•ì ì¸ ê³¼ì í•© ìƒíƒœ.
* **í–¥í›„ ê³¼ì œ:** ë‹¤ìŒ ë‹¨ê³„ì—ì„œ Dropout ì¶”ê°€ ë° Regularization ê¸°ë²•ì„ ì ìš©í•˜ì—¬ ëª¨ë¸ì˜ ì¼ë°˜í™”(Generalization) ì„±ëŠ¥ì„ ê°œì„ í•  ì˜ˆì •.

## 11. Overfitting Prevention: Dropout & Regularization

í•™ìŠµ ê²°ê³¼ ë‚˜íƒ€ë‚œ ì „í˜•ì ì¸ ê³¼ì í•©(Overfitting) ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ëª¨ë¸ ì„¤ê³„ì— ë‘ ê°€ì§€ í•µì‹¬ ê·œì œ ê¸°ë²•ì„ ë„ì…í•˜ì˜€ìŠµë‹ˆë‹¤. 

### ğŸŸ¢ ê°œì„ ëœ ëª¨ë¸ êµ¬ì¡° (Updated Model Architecture)
ê¸°ì¡´ ëª¨ë¸ì— `Dropout`ê³¼ `L2 Regularizer`ë¥¼ ì ìš©í•œ ìµœì¢… ì‹ ê²½ë§ êµ¬ì¡°ì…ë‹ˆë‹¤.

| Layer (type) | Output Shape | Param # |
|:--- |:--- |:--- |
| **flatten (Flatten)** | (None, 1690) | 0 |
| **dense (Dense)** | (None, 512) | 865,792 |
| **dropout (Dropout)** | (None, 512) | 0 |
| **dense_1 (Dense)** | (None, 256) | 131,328 |
| **dropout_1 (Dropout)** | (None, 256) | 0 |
| **dense_2 (Dense)** | (None, 64) | 16,448 |
| **dropout_2 (Dropout)** | (None, 64) | 0 |
| **dense_3 (Dense)** | (None, 10) | 650 |



### 11.1 L2 ê°€ì¤‘ì¹˜ ê·œì œ (Weight Decay)
* **ì ìš©**: `kernel_regularizer=keras.regularizers.l2(0.001)`
* **ì›ë¦¬**: ì†ì‹¤ í•¨ìˆ˜ì— ê°€ì¤‘ì¹˜ì˜ ì œê³±ì— ë¹„ë¡€í•˜ëŠ” í˜ë„í‹°ë¥¼ ì¶”ê°€í•˜ì—¬ ê°€ì¤‘ì¹˜ í­ì£¼ë¥¼ ì–µì œ.
* **íš¨ê³¼**: ëª¨ë¸ì´ íŠ¹ì • í›ˆë ¨ ìƒ˜í”Œì˜ íŠ¹ì´ì¹˜(Outlier)ì— ë¯¼ê°í•˜ê²Œ ë°˜ì‘í•˜ì§€ ì•Šë„ë¡ ê°€ì¤‘ì¹˜ë¥¼ ìœ ì§€í•˜ê²Œ í•˜ì—¬ ì¼ë°˜í™” ì„±ëŠ¥ì„ í–¥ìƒ.

### 11.2 ë“œë¡­ì•„ì›ƒ (Dropout) ë ˆì´ì–´ ì¶”ê°€
* **ì ìš©**: `keras.layers.Dropout(0.3)` (ê° ì€ë‹‰ì¸µ ë’¤ì— ë°°ì¹˜)
* **ì›ë¦¬**: ë§¤ ì—…ë°ì´íŠ¸ë§ˆë‹¤ ë‰´ëŸ°ì˜ 30%ë¥¼ ë¬´ì‘ìœ„ë¡œ ë¹„í™œì„±í™”í•˜ì—¬ íŠ¹ì • ë‰´ëŸ° ì‚¬ì´ì˜ ìƒí˜¸ì˜ì¡´ì„±(Co-adaptation)ì„ ì œê±°.
* **íš¨ê³¼**: ëª¨ë¸ì´ ë‹¤ìˆ˜ì˜ ë…ë¦½ì ì¸ íŠ¹ì§•ì„ í•™ìŠµí•˜ë„ë¡ ê°•ì œí•˜ì—¬, ë§ˆì¹˜ ì—¬ëŸ¬ ê°œì˜ ëª¨ë¸ì„ ì•™ìƒë¸”(Ensemble)í•œ ê²ƒê³¼ ê°™ì€ ê°•ë ¥í•œ ì¼ë°˜í™” íš¨ê³¼ë¥¼ ì–»ìŒ.

### 11.3 ê³¼ì í•© í•´ê²° ê²°ê³¼ ë¶„ì„ (Overfitting Solved)

ëª¨ë¸ì— **L2 ê·œì œ**ì™€ **Dropout**ì„ ì ìš©í•œ í›„, ì‹œê°í™” ì§€í‘œë¥¼ í†µí•´ ë‹¤ìŒê³¼ ê°™ì€ ìœ ì˜ë¯¸í•œ ë³€í™”ë¥¼ í™•ì¸.

* **ê·¸ë˜í”„ ê°„ê²©(Gap) ì¶•ì†Œ**: í›ˆë ¨ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ ì •í™•ë„/ì˜¤ì°¨ ê³¡ì„ ì´ ì´ì „ë³´ë‹¤ í›¨ì”¬ ì¸ì ‘í•˜ê²Œ í˜•ì„±ë©ë‹ˆë‹¤. ì´ëŠ” ëª¨ë¸ì´ ì•”ê¸°ê°€ ì•„ë‹Œ 'í•™ìŠµ'ì„ í•˜ê³  ìˆìŒì„ ì¦ëª….
* **ê²€ì¦ ì˜¤ì°¨(Validation Loss) ì•ˆì •í™”**: ì—í¬í¬ê°€ ì§„í–‰ë¨ì— ë”°ë¼ ê²€ì¦ ì˜¤ì°¨ê°€ ê¸‰ê²©íˆ ì¹˜ì†Ÿë˜ í˜„ìƒì´ ì–µì œë˜ê³ , ì¼ì • ìˆ˜ì¤€ì—ì„œ ì•ˆì •ì ìœ¼ë¡œ ìœ ì§€.
* **ì¼ë°˜í™” ì„±ëŠ¥ í™•ë³´**: ë¹„ë¡ í›ˆë ¨ ì •í™•ë„ëŠ” ì´ì „ë³´ë‹¤ ë‹¤ì†Œ ë‚®ì•„ì§ˆ ìˆ˜ ìˆìœ¼ë‚˜(ì•”ê¸°ë¥¼ ëª» í•˜ê²Œ ë§‰ì•˜ìœ¼ë¯€ë¡œ), ì‹¤ì œ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•œ ëŒ€ì‘ ëŠ¥ë ¥ì€ ë¹„ì•½ì ìœ¼ë¡œ í–¥ìƒ.

![overfitting_solved](./image/260212_overfitting_solved.png)

### 11.4 ê¸°íƒ€ ê³¼ì í•© ë°©ì§€ ì „ëµ (Alternative Strategies)

ì´ë²ˆ í”„ë¡œì íŠ¸ì—ì„œ ì£¼ë ¥ìœ¼ë¡œ ì‚¬ìš©í•œ ê¸°ë²• ì™¸ì—ë„, ë”¥ëŸ¬ë‹ ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•´ ê³ ë ¤í•  ìˆ˜ ìˆëŠ” ë³´ì¡° ì „ëµë“¤ì€ ë‹¤ìŒê³¼ ê°™ìŒ.

1.  **ëª¨ë¸ ë‹¨ìˆœí™” (Simpler Architecture)**
    * **ë°©ë²•**: ì€ë‹‰ì¸µì˜ ê°œìˆ˜ë‚˜ ê° ì¸µì˜ ë‰´ëŸ°(Node) ìˆ˜ë¥¼ ì¤„ì„.
    * **ì´ìœ **: ëª¨ë¸ì˜ í•™ìŠµ ìš©ëŸ‰(Capacity) ìì²´ë¥¼ ì¤„ì—¬, ë³µì¡í•œ ë…¸ì´ì¦ˆê¹Œì§€ í•™ìŠµí•  ì—¬ìœ ë¥¼ ì£¼ì§€ ì•ŠëŠ” ì›ì´ˆì ì¸ ë°©ë²•.

2.  **ë°ì´í„° ì¦ê°• (Data Augmentation)**
    * **ë°©ë²•**: ê¸°ì¡´ ìŒì› ë°ì´í„°ë¥¼ ì†ë„ ì¡°ì ˆ(Time Stretching), ìŒë†’ì´ ë³€ê²½(Pitch Shifting), ì†ŒìŒ ì¶”ê°€(Noise Injection) ë“±ìœ¼ë¡œ ë³€í˜•í•˜ì—¬ ë°ì´í„° ì–‘ì„ ì–µì œì ìœ¼ë¡œ ëŠ˜ë¦¼.

3.  **ì¡°ê¸° ì¢…ë£Œ (Early Stopping)**
    * **ë°©ë²•**: ê²€ì¦ ì˜¤ì°¨(Validation Loss)ê°€ ë” ì´ìƒ ì¤„ì–´ë“¤ì§€ ì•Šê³  ìƒìŠ¹í•˜ê¸° ì‹œì‘í•˜ëŠ” ì‹œì ì—ì„œ í•™ìŠµì„ ê°•ì œë¡œ ì¤‘ë‹¨.

## 12. CNN Implementation for Genre Classification

MLP(ë‹¤ì¸µ í¼ì…‰íŠ¸ë¡ )ì˜ í•œê³„ë¥¼ ë„˜ì–´, ì´ë¯¸ì§€ ì²˜ë¦¬ ë¶„ì•¼ì—ì„œ í˜ëª…ì ì¸ ì„±ê³¼ë¥¼ ë‚¸ **CNN(Convolutional Neural Network)**ì„ ì˜¤ë””ì˜¤ ë°ì´í„°(MFCC)ì— ì ìš©í•¨.

### 12.1 Why CNN for Audio? (MLP vs CNN)
* **MLPì˜ í•œê³„:** 2ì°¨ì›ì¸ MFCC ë°ì´í„°(ì‹œê°„ Ã— ì£¼íŒŒìˆ˜)ë¥¼ 1ì°¨ì›ìœ¼ë¡œ ì­‰ í´ì„œ(`Flatten`) ì…ë ¥ë°›ê¸° ë•Œë¬¸ì—, ì†Œë¦¬ì˜ **ì‹œê°„ì  íë¦„(Time)**ê³¼ **ì£¼íŒŒìˆ˜ ê°„ì˜ ê´€ê³„(Structure)** ì •ë³´ê°€ ì†ì‹¤ë¨.
* **CNNì˜ ì ‘ê·¼:** MFCC ìŠ¤í™íŠ¸ë¡œê·¸ë¨ì„ ë§ˆì¹˜ **'í‘ë°± ì´ë¯¸ì§€'**ì²˜ëŸ¼ ì·¨ê¸‰í•¨.
    * **Local Invariance:** ì´ë¯¸ì§€ì—ì„œ ì‚¬ë¬¼ì˜ ìœ„ì¹˜ê°€ ë°”ë€Œì–´ë„ ì¸ì‹í•˜ëŠ” ê²ƒì²˜ëŸ¼, ì†Œë¦¬ì˜ ë†’ë‚®ì´ë‚˜ ì‹œê°„ëŒ€ê°€ ì¡°ê¸ˆ ë‹¬ë¼ì ¸ë„ ê³ ìœ í•œ íŠ¹ì§•(Feature)ì„ ì¡ì•„ë‚¼ ìˆ˜ ìˆìŒ.
    * **Parameter Sharing:** ì‘ì€ í•„í„°(Kernel)ë¥¼ ë°˜ë³µ ì‚¬ìš©í•˜ë¯€ë¡œ, MLP ëŒ€ë¹„ í›¨ì”¬ ì ì€ íŒŒë¼ë¯¸í„°ë¡œ íš¨ìœ¨ì ì¸ í•™ìŠµì´ ê°€ëŠ¥í•¨.

### 12.2 Data Preprocessing for CNN (3D Input)
CNNì€ ê¸°ë³¸ì ìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆê¸°ì—, 2ì°¨ì› ë°°ì—´ì¸ MFCC ë°ì´í„°ì— **'ì±„ë„(Channel)'** ì°¨ì›ì„ ì¶”ê°€í•˜ì—¬ 3ì°¨ì› êµ¬ì¡°ë¡œ ë³€í™˜í•´ì•¼ í•¨.

* **Original MFCC:** `(130, 13)` -> [ì‹œê°„, ì£¼íŒŒìˆ˜]
* **CNN Input:** `(130, 13, 1)` -> [ì‹œê°„, ì£¼íŒŒìˆ˜, **ì±„ë„(1)**]
    * `np.newaxis`ë¥¼ ì‚¬ìš©í•˜ì—¬ ê¹Šì´(Depth)ê°€ 1ì¸ 3ì°¨ì› í…ì„œë¡œ í™•ì¥í•¨. (ë§ˆì¹˜ RGB ì±„ë„ì´ ì—†ëŠ” í‘ë°± ì‚¬ì§„ê³¼ ë™ì¼í•œ êµ¬ì¡°)

### 12.3 Model Architecture & Key Components
3ê°œì˜ Convolution Layer ë¸”ë¡ê³¼ Classifier(Dense)ë¡œ êµ¬ì„±ëœ ëª¨ë¸ êµ¬ì¡°ì„.

#### 1) Convolution Block (Feature Extraction)
* **Conv2D:** `(3, 3)` í¬ê¸°ì˜ ì‘ì€ í•„í„° 32ê°œê°€ ë°ì´í„°ë¥¼ í›‘ìœ¼ë©° ìˆ˜ì§/ìˆ˜í‰ì„ ì˜ íŠ¹ì§•ì„ ê°ì§€í•¨. ì¸µì´ ê¹Šì–´ì§ˆìˆ˜ë¡ ë” ë³µì¡í•˜ê³  ì¶”ìƒì ì¸ ì†Œë¦¬ì˜ íŒ¨í„´ì„ í•™ìŠµí•¨.
* **MaxPooling2D:** `(2, 2)` í¬ê¸°ë¡œ ë°ì´í„°ë¥¼ ì••ì¶•í•¨. ì¤‘ìš”í•œ íŠ¹ì§•ì€ ë‚¨ê¸°ê³  ë¶ˆí•„ìš”í•œ ì •ë³´ëŠ” ë²„ë ¤ ì—°ì‚°ëŸ‰ì„ ì¤„ì´ê³  ê³¼ì í•©ì„ ë°©ì§€í•¨.
* **Batch Normalization (í•µì‹¬):**
    * **ë¬¸ì œ (Internal Covariate Shift):** í•™ìŠµ ë„ì¤‘ ì´ì „ ì¸µì˜ ê°€ì¤‘ì¹˜ê°€ ë³€í•˜ë©´, ë‹¤ìŒ ì¸µìœ¼ë¡œ ë„˜ì–´ê°€ëŠ” ë°ì´í„°ì˜ ë¶„í¬ê°€ ë„ë›°ê¸°ë¥¼ í•˜ì—¬ í•™ìŠµì´ ë¶ˆì•ˆì •í•´ì§.
    * **í•´ê²°:** ê° ì¸µì˜ ì¶œë ¥ê°’ì„ ê°•ì œë¡œ **í‰ê·  0, ë¶„ì‚° 1**ë¡œ ì •ë ¬(Normalize)í•´ ì¤Œ.
    * **íš¨ê³¼:** í•™ìŠµ ì†ë„ê°€ ë¹„ì•½ì ìœ¼ë¡œ ë¹¨ë¼ì§€ê³ , ì´ˆê¸° ì„¤ì •ì— ëœ ë¯¼ê°í•´ì§€ë©° ì•ˆì •ì ì¸ í•™ìŠµì´ ê°€ëŠ¥í•´ì§.

#### 2) Classification Head
* **Flatten:** 3ì°¨ì› íŠ¹ì§•ë§µ(Feature Map)ì„ 1ì°¨ì› ë²¡í„°ë¡œ í¼ì¹¨.
* **Dense (64 nodes):** ì¶”ì¶œëœ íŠ¹ì§•ë“¤ì„ ì¡°í•©í•˜ì—¬ ìµœì¢… íŒë‹¨ì„ ë‚´ë¦¼.
* **Dropout (0.3):** ë‰´ëŸ°ì˜ 30%ë¥¼ êº¼ì„œ ê³¼ì í•©ì„ ì–µì œ.
* **Output (Softmax):** 10ê°œ ì¥ë¥´ì— ëŒ€í•œ ìµœì¢… í™•ë¥  ì¶œë ¥.

### 12.4 Prediction Logic & Dimension Expansion
í•™ìŠµëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ê°œë³„ ìƒ˜í”Œì„ ì˜ˆì¸¡(`predict`)í•  ë•Œ, ë°ì´í„°ì˜ ì°¨ì›ì„ ë§ì¶”ëŠ” ê²ƒì´ ë§¤ìš° ì¤‘ìš”í•¨. ëª¨ë¸ì€ í•­ìƒ **'ë°°ì¹˜(Batch)'** ë‹¨ìœ„ì˜ ì…ë ¥ì„ ê¸°ëŒ€í•˜ê¸° ë•Œë¬¸.

```python
def predict(model, X, Y):
    # 1. ì°¨ì› í™•ì¥ (Batch Dimension ì¶”ê°€)
    # -------------------------------------------------------------------------
    # í˜„ì¬ X: (130, 13, 1) -> "ë°ì´í„° 1ê°œ"
    # ëª¨ë¸ ê¸°ëŒ€ ì…ë ¥: (Batch, Time, Freq, Channel) -> "ë°ì´í„° ë¬¶ìŒ"
    # í•´ê²°: np.newaxisë¥¼ ë§¨ ì•ì— ì¶”ê°€í•˜ì—¬ "1ê°œì§œë¦¬ ë¬¶ìŒ"ìœ¼ë¡œ í¬ì¥í•¨.
    # ë³€í™˜: (130, 13, 1) -> (1, 130, 13, 1)
    X = X[np.newaxis, ...] 

    # 2. ì˜ˆì¸¡ (Inference)
    # ê²°ê³¼: [[0.1, 0.05, 0.8, ...]] (ê° í´ë˜ìŠ¤ë³„ í™•ë¥  ë¦¬ìŠ¤íŠ¸)
    prediction = model.predict(X)

    # 3. ê²°ê³¼ í•´ì„
    # ê°€ì¥ ë†’ì€ í™•ë¥ ì„ ê°€ì§„ ì¸ë±ìŠ¤ ì¶”ì¶œ (Argmax)
    predicted_index = np.argmax(prediction, axis=1)
    
    # 4. ì •ë‹µ ë¹„êµ
    print(f"Expected index: {Y}, Predicted index: {predicted_index}")
```
### 12.5 Final Result Analysis
* **Test Accuracy:** ì•½ **72.5%** ë‹¬ì„±.
* **Performance:** 10ê°œ ì¥ë¥´ ì¤‘ ë¬´ì‘ìœ„ ì„ íƒ í™•ë¥ (10%) ëŒ€ë¹„ **ì•½ 7ë°° ì´ìƒ** ë†’ì€ ì •í™•ë„ë¥¼ ë³´ì„.
* **Training vs Test Gap:** Train Accuracy(74.8%)ì™€ Test Accuracy(72.5%)ì˜ ê²©ì°¨ê°€ ì•½ **2.3%p**ë¡œ ë§¤ìš° ì ìŒ. ì´ëŠ” **ê³¼ì í•©(Overfitting) ì—†ì´ ëª¨ë¸ì´ ì•„ì£¼ ê±´ê°•í•˜ê²Œ í•™ìŠµë˜ì—ˆìŒ**ì„ ì˜ë¯¸í•¨.
* **Conclusion:** ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ë¡œì„œ í›Œë¥­í•œ ì„±ëŠ¥ì„ í™•ë³´í•¨. í–¥í›„ Data Augmentation(ë°ì´í„° ì¦ê°•)ì´ë‚˜ ëª¨ë¸ì˜ ê¹Šì´(Depth)ë¥¼ í™•ì¥í•˜ì—¬ 80% ì´ìƒì˜ ì •í™•ë„ì— ë„ì „í•  ê³„íšì„.